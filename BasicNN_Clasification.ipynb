{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013ab746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NOTE: librosa dependencies apparently require specific versions of numpy, try numpy==1.21.4\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c806a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df = pd.read_csv('./large_data/eq_harmony_combined.csv')\n",
    "# display(eq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063bb1c1",
   "metadata": {},
   "source": [
    "After initial attempts performed relatively poorly, I decided to try to add another classifier object. Crest factor is the ratio of the maximum amplitude of a signal to its root mean square. As such, I expect short, loud sounds like gunshots to exhibit large crest factors.\n",
    "\n",
    "After initial attempts with the crest factor I noticed that a number of the audio samples have significant \"room noise\" present. In an attempt to clean this up I'm taking the hilbert transform (extracts the instantaneous amplitude of a signal). Smoothing this transform and dividing by the root mean square power should then amplify the parts of the signal that are large in amplitude, while minimizing the areas that are simply a constant amplitude \"hum\". Low crest factor systems will be largely unaffected as the root mean square will be similar to the root mean square of the signal for such signals. Finally we ensure that the maximum amplitude of the signal is scaled to be equal to the input signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ba585",
   "metadata": {},
   "outputs": [],
   "source": [
    "nansvec = np.isnan(eq_df['crestfactor'])\n",
    "nansvec[nansvec==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe20df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df['power_ratio'] = np.log10(eq_df['percussive_power'].values / (eq_df['harmonic_power'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df['hits_ratio'] = np.log10(eq_df['percussive_hits'].values / (eq_df['harmonic_hits'].values + 1e-1) + 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "sns.stripplot(data = eq_df,\n",
    "             x = 'class',\n",
    "             y = 'crestfactor')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df = eq_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nansvec = np.isnan(eq_df['crestfactor'])\n",
    "nansvec[nansvec==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try classifying with the log instead?\n",
    "for i in range(0,len(eq_df)):\n",
    "    eq_df.iloc[i,1:-9] = np.log10(eq_df.iloc[i,1:-9].values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPR(prediction, data, numclasses):\n",
    "    \"\"\"\n",
    "    Returns True Positive Ratio given a prediction and data\n",
    "    \"\"\"\n",
    "    confmat = confusion_matrix(prediction, data)\n",
    "\n",
    "#     TN = confmat[0,0]\n",
    "#     FP = confmat[0,1]\n",
    "#     FN = confmat[1,0]\n",
    "#     TP = confmat[1,1]\n",
    "    TP = np.zeros(numclasses)\n",
    "    FN = np.zeros(numclasses)\n",
    "    R = np.zeros(numclasses)\n",
    "    for i in range(numclasses):\n",
    "        TP[i] = confmat[i,i]\n",
    "        FN[i] = confmat[i,:].sum() - confmat[i,i]\n",
    "    \n",
    "    R = TP/(TP + FN)\n",
    "    \n",
    "    \n",
    "    return R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(prediction, data, numclasses):\n",
    "    \"\"\"\n",
    "    Calculates recall of a prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    confmat = confusion_matrix(prediction, data)\n",
    "\n",
    "#     TN = confmat[0,0]\n",
    "#     FP = confmat[0,1]\n",
    "#     FN = confmat[1,0]\n",
    "#     TP = confmat[1,1]\n",
    "#     TP = confmat[6,6]\n",
    "#     FN = confmat[6,:] - confmat[6,6]\n",
    "    TP = np.zeros(numclasses)\n",
    "    R = np.zeros(numclasses)\n",
    "    FN = np.zeros(numclasses)\n",
    "    for i in range(numclasses):\n",
    "        TP[i] = confmat[i,i]\n",
    "        FN[i] = confmat[i,:].sum() - confmat[i,i]\n",
    "    \n",
    "    R = TP/(TP + FN)\n",
    "    \n",
    "    return R\n",
    "\n",
    "def precision(prediction, data,numclasses):\n",
    "    \"\"\"\n",
    "    Calculates precision of a prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    confmat = confusion_matrix(prediction, data)\n",
    "\n",
    "#     TN = confmat[0,0]\n",
    "#     FP = confmat[0,1]\n",
    "#     FN = confmat[1,0]\n",
    "#     TP = confmat[1,1]\n",
    "#     TP = confmat[6,6]\n",
    "#     FP = confmat[:,6].sum() - confmat[6,6]\n",
    "    TP = np.zeros(numclasses)\n",
    "    FP = np.zeros(numclasses)\n",
    "    P = np.zeros(numclasses)\n",
    "    for i in range(numclasses):\n",
    "        TP[i] = confmat[i,i]\n",
    "        FP[i] = confmat[:,i].sum() - confmat[i,i]\n",
    "    \n",
    "    P = TP/(TP + FP)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fmeasure(prediction, data, numclasses):\n",
    "    \"\"\"\n",
    "    Returns Fmeasure. \n",
    "    \n",
    "    This is considered a balance of the precision and the recall.\n",
    "    \n",
    "    F = (2*P*R)/(P+R)\n",
    "    \n",
    "    where\n",
    "    \n",
    "    P = TP/(TP + FP) is the precision and\n",
    "    R = TP/(TP + FN) is the recall.\n",
    "    \n",
    "    Reference: \n",
    "    MÃ¼ller, Meinard. Fundamentals of music processing: Audio, analysis, algorithms, applications. \n",
    "    Vol. 5. Cham: Springer, 2015.\n",
    "    Sec. 4.5 pp. 217\n",
    "    \"\"\"\n",
    "    confmat = confusion_matrix(prediction, data)\n",
    "\n",
    "#     TN = confmat[0,0]\n",
    "#     FP = confmat[0,1]\n",
    "#     FN = confmat[1,0]\n",
    "#     TP = confmat[1,1]\n",
    "#     TP = confmat[6,6]\n",
    "#     FN = confmat[6,:].sum() - confmat[6,6]\n",
    "#     FP = confmat[:,6].sum() - confmat[6,6]\n",
    "    TP = np.zeros(numclasses)\n",
    "    FN = np.zeros(numclasses)\n",
    "    FP = np.zeros(numclasses)\n",
    "    P = np.zeros(numclasses)\n",
    "    R = np.zeros(numclasses)\n",
    "    for i in range(numclasses):\n",
    "        TP[i] = confmat[i,i]\n",
    "        FN[i] = confmat[i,:].sum() - confmat[i,i]\n",
    "        FP[i] = confmat[:,i].sum() - confmat[i,i]\n",
    "    \n",
    "    P = TP/(TP + FP)\n",
    "    R = TP/(TP + FN)\n",
    "    \n",
    "    F = (2*P*R)/(P + R)\n",
    "\n",
    "    return F\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083354b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da41282",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df2 = eq_df.copy()\n",
    "eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "                'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9},inplace=True)\n",
    "# eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "#                 'engine_idling':0, 'gun_shot':5, 'jackhammer':4, 'siren':6, 'street_music':2},inplace=True)\n",
    "# eq_df2.replace({'air_conditioner':0, 'car_horn':0, 'children_playing':0, 'dog_bark':0, 'drilling':0,\n",
    "#                 'engine_idling':0, 'gun_shot':1, 'jackhammer':0, 'siren':0, 'street_music':0},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232aa2e",
   "metadata": {},
   "source": [
    "Documentation of the dataset suggests not shuffling the dataset. This is because there are a number of audio files that are taken as sections from longer audio files and will result in anomalous results if these are shuffled together. Instead the dataset has included a psuedorandom \"fold\" category to serve as splits for cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7665db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropfold = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df3 = eq_df2.drop(eq_df2[eq_df2['fold']==dropfold].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01156732",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df3[eq_df3['fold']==dropfold].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1999f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df3.drop(columns='fold',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df3.iloc[1,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = eq_df3.iloc[:,1:].values\n",
    "# X_train = [eq_df3.iloc[:,1:-2].values, eq_df3.iloc[:,-1]]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf52883",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = eq_df3.iloc[:,0].values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = eq_df2[eq_df2['fold'] == dropfold].copy()\n",
    "X_val.drop(columns='fold',inplace=True)\n",
    "X_val.drop(columns='salience',inplace=True)\n",
    "X_val = X_val.iloc[:,1:].values\n",
    "y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "y_val = y_val.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isinf(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4839e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53583a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20438f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed26cfc",
   "metadata": {},
   "source": [
    "Here we consider the True Positive Rate for the gunshot data as an indicator of the goodness of fit. Interestingly this is often higher when the classifier can classify into multiple categories than simply gunshot/not gunshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801fc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confmat = confusion_matrix(y_train, mlp.predict(X_train))\n",
    "# acc = 100*confmat[1,1] / (np.sum(np.sum(confmat[1,:])))\n",
    "# print(\"Training accuracy of\", acc)\n",
    "# confmat = confusion_matrix(y_val, mlp.predict(X_val))\n",
    "# acc = 100*confmat[1,1] / (np.sum(confmat[1,:]))\n",
    "# print(\"Validation accuracy of\", acc)\n",
    "\n",
    "# confmat = confusion_matrix(y_train, mlp.predict(X_train))\n",
    "# acc = 100*confmat[6,6] / (np.sum(np.sum(confmat[6,:])))\n",
    "acc =100*TPR(y_train, mlp.predict(X_train),10)\n",
    "acc2 =100*Fmeasure(y_train, mlp.predict(X_train),10)\n",
    "plt.scatter(range(10),acc)\n",
    "# print(\"Training TPR of\", acc, \"Fmeasure of\", acc2)\n",
    "# confmat = confusion_matrix(y_val, mlp.predict(X_val))\n",
    "# acc = 100*confmat[6,6] / (np.sum(confmat[6,:]))\n",
    "acc = 100*TPR(y_val, mlp.predict(X_val),10)\n",
    "acc2 = 100*Fmeasure(y_val, mlp.predict(X_val),10)\n",
    "plt.scatter(range(10),acc)\n",
    "# print(\"Validation TPR of\", acc, \"Fmeasure of\", acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_val, mlp.predict(X_val)),\n",
    "            columns=[\"predicted \"+str(i) for i in range(10)],\n",
    "            index=[\"actual \"+str(i) for i in range(10)])\n",
    "\n",
    "# pd.DataFrame(confusion_matrix(y_val, mlp.predict(X_val)),\n",
    "#             columns=[\"predicted \"+str(i) for i in range(2)],\n",
    "#             index=[\"actual \"+str(i) for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c713d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabels = {'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4, 'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797154e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_val, mlp.predict(X_val)),display_labels=classlabels)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b56c63",
   "metadata": {},
   "source": [
    "As suggested by the dataset the most accurate results for a classifier are acheived when averaged over the different possible test/validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ea5a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy_vec = np.zeros(10)\n",
    "for dropfold in range(1,11):\n",
    "    eq_df2 = eq_df.copy()\n",
    "    eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "                'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "#                 'engine_idling':0, 'gun_shot':6, 'jackhammer':4, 'siren':8, 'street_music':2},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':0, 'children_playing':0, 'dog_bark':0, 'drilling':0,\n",
    "#                     'engine_idling':0, 'gun_shot':1, 'jackhammer':0, 'siren':0, 'street_music':0},inplace=True)\n",
    "\n",
    "    eq_df3 = eq_df2.drop(eq_df2[eq_df2['fold']==dropfold].index)\n",
    "    eq_df3.drop(columns='fold',inplace=True)\n",
    "    eq_df3.drop(columns='salience',inplace=True)\n",
    "    X_train = eq_df3.iloc[:,1:].values\n",
    "    y_train = eq_df3.iloc[:,0].values\n",
    "    \n",
    "#     X_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     X_val = X_val.iloc[:,1:].values\n",
    "#     y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    X_val = eq_df2[eq_df2['fold'] == dropfold].copy()\n",
    "    X_val.drop(columns='fold',inplace=True)\n",
    "    X_val.drop(columns='salience',inplace=True)\n",
    "    X_val = X_val.iloc[:,1:].values\n",
    "    y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "    y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "    mlp.fit(X_train, y_train)\n",
    "#     acc = 100*Fmeasure(y_val, mlp.predict(X_val),7)\n",
    "    recall = np.round(100*TPR(y_val, mlp.predict(X_val),10)[6],2)\n",
    "    prec = np.round(100*precision(y_val, mlp.predict(X_val),10)[6],2)\n",
    "    Fmeas = np.round(100*Fmeasure(y_val, mlp.predict(X_val),10)[6],2)\n",
    "#     acc = 100*TPR(y_val, mlp.predict(X_val),7)[5]\n",
    "    print(\"Validation TPR of\", recall, \",\\n \\tprecision of \", prec, \",\\n \\tand Fmeasure of\", Fmeas, \"on fold\", str(dropfold))\n",
    "    accuracy_vec[dropfold-1] = recall\n",
    "    \n",
    "print(accuracy_vec)\n",
    "accuracy_vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.predict_proba(X_val)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556839aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vec = np.zeros(10)\n",
    "for dropfold in range(1,11):\n",
    "    eq_df2 = eq_df.copy()\n",
    "    eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "                'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "#                 'engine_idling':0, 'gun_shot':6, 'jackhammer':4, 'siren':8, 'street_music':2},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':0, 'children_playing':0, 'dog_bark':0, 'drilling':0,\n",
    "#                     'engine_idling':0, 'gun_shot':1, 'jackhammer':0, 'siren':0, 'street_music':0},inplace=True)\n",
    "\n",
    "    eq_df3 = eq_df2.drop(eq_df2[eq_df2['fold']==dropfold].index)\n",
    "    eq_df3.drop(columns='fold',inplace=True)\n",
    "    eq_df3.drop(columns='salience',inplace=True)\n",
    "    X_train = eq_df3.iloc[:,1:].values\n",
    "    y_train = eq_df3.iloc[:,0].values\n",
    "    \n",
    "#     X_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     X_val = X_val.iloc[:,1:].values\n",
    "#     y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    X_val = eq_df2[eq_df2['fold'] == dropfold].copy()\n",
    "    X_val.drop(columns='fold',inplace=True)\n",
    "    X_val.drop(columns='salience',inplace=True)\n",
    "    X_val = X_val.iloc[:,1:].values\n",
    "    y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "    y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    mlp1 = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "    mlp2 = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "    mlp3 = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "    mlp4 = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "    mlp5 = MLPClassifier(hidden_layer_sizes=(150,150,150,150,150,), max_iter=100000, early_stopping=True)\n",
    "\n",
    "\n",
    "#     mlp.fit(X_train, y_train)\n",
    "    vote_class = VotingClassifier(estimators=[\n",
    "                 ('mlp1', mlp1), ('mlp2', mlp2), ('mlp3', mlp3), ('mlp4', mlp4), ('mlp5', mlp5)],\n",
    "                 voting='soft')\n",
    "    vote_class = vote_class.fit(X_train, y_train)\n",
    "#     acc = 100*Fmeasure(y_val, mlp.predict(X_val),7)\n",
    "    recall = np.round(100*TPR(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    prec = np.round(100*precision(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    Fmeas = np.round(100*Fmeasure(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "#     acc = 100*TPR(y_val, mlp.predict(X_val),7)[5]\n",
    "    print(\"Validation TPR of\", recall, \",\\n \\tprecision of \", prec, \",\\n \\tand Fmeasure of\", Fmeas, \"on fold\", str(dropfold))\n",
    "    accuracy_vec[dropfold-1] = recall\n",
    "    \n",
    "print(accuracy_vec)\n",
    "accuracy_vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(round(np.random.rand()*200,0)+50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randlayer():\n",
    "    return int(round(np.random.rand()*200,0)+50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vec = np.zeros(10)\n",
    "for dropfold in range(1,11):\n",
    "    eq_df2 = eq_df.copy()\n",
    "    eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "                'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "#                 'engine_idling':0, 'gun_shot':6, 'jackhammer':4, 'siren':8, 'street_music':2},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':0, 'children_playing':0, 'dog_bark':0, 'drilling':0,\n",
    "#                     'engine_idling':0, 'gun_shot':1, 'jackhammer':0, 'siren':0, 'street_music':0},inplace=True)\n",
    "\n",
    "    eq_df3 = eq_df2.drop(eq_df2[eq_df2['fold']==dropfold].index)\n",
    "    eq_df3.drop(columns='fold',inplace=True)\n",
    "    eq_df3.drop(columns='salience',inplace=True)\n",
    "    X_train = eq_df3.iloc[:,1:].values\n",
    "    y_train = eq_df3.iloc[:,0].values\n",
    "    \n",
    "#     X_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     X_val = X_val.iloc[:,1:].values\n",
    "#     y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    X_val = eq_df2[eq_df2['fold'] == dropfold].copy()\n",
    "    X_val.drop(columns='fold',inplace=True)\n",
    "    X_val.drop(columns='salience',inplace=True)\n",
    "    X_val = X_val.iloc[:,1:].values\n",
    "    y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "    y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    mlp1 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp2 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp3 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp4 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp5 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp6 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp7 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp8 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp9 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp10 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp11 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp12 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp13 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp14 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp15 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp16 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp17 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp18 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp19 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "    mlp20 = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)\n",
    "\n",
    "\n",
    "#     mlp.fit(X_train, y_train)\n",
    "    vote_class = VotingClassifier(estimators=[\n",
    "                 ('mlp1', mlp1), ('mlp2', mlp2), ('mlp3', mlp3), ('mlp4', mlp4), ('mlp5', mlp5),\n",
    "                    ('mlp6', mlp6), ('mlp7', mlp7), ('mlp8', mlp8), ('mlp9', mlp9), ('mlp10', mlp10),\n",
    "                    ('mlp11', mlp11), ('mlp12', mlp12), ('mlp13', mlp13), ('mlp14', mlp14), ('mlp15', mlp15),\n",
    "                    ('mlp16', mlp16), ('mlp17', mlp17), ('mlp18', mlp18), ('mlp19', mlp19), ('mlp20', mlp20)],\n",
    "                 voting='soft', n_jobs=4)\n",
    "    vote_class = vote_class.fit(X_train, y_train)\n",
    "#     acc = 100*Fmeasure(y_val, mlp.predict(X_val),7)\n",
    "    recall = np.round(100*TPR(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    prec = np.round(100*precision(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    Fmeas = np.round(100*Fmeasure(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "#     acc = 100*TPR(y_val, mlp.predict(X_val),7)[5]\n",
    "    print(\"Validation TPR of\", recall, \",\\n \\tprecision of \", prec, \",\\n \\tand Fmeasure of\", Fmeas, \"on fold\", str(dropfold))\n",
    "    accuracy_vec[dropfold-1] = recall\n",
    "    \n",
    "print(accuracy_vec)\n",
    "accuracy_vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = 'mlp'+str(1)\n",
    "print(teststr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5575282",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('mlp'+str(21)+' = MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0686deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voter_tuple(i):\n",
    "    teststr = 'mlp'+str(i)\n",
    "    return (teststr, MLPClassifier(hidden_layer_sizes=(randlayer(),randlayer(),randlayer(),randlayer(),randlayer(),), max_iter=100000, early_stopping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc28c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_tuple(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_voters=2\n",
    "accuracy_vec = np.zeros(10)\n",
    "for dropfold in range(1,11):\n",
    "    eq_df2 = eq_df.copy()\n",
    "    eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "                'engine_idling':5, 'gun_shot':6, 'jackhammer':7, 'siren':8, 'street_music':9},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':1, 'children_playing':2, 'dog_bark':3, 'drilling':4,\n",
    "#                 'engine_idling':0, 'gun_shot':6, 'jackhammer':4, 'siren':8, 'street_music':2},inplace=True)\n",
    "#     eq_df2.replace({'air_conditioner':0, 'car_horn':0, 'children_playing':0, 'dog_bark':0, 'drilling':0,\n",
    "#                     'engine_idling':0, 'gun_shot':1, 'jackhammer':0, 'siren':0, 'street_music':0},inplace=True)\n",
    "\n",
    "    eq_df3 = eq_df2.drop(eq_df2[eq_df2['fold']==dropfold].index)\n",
    "    eq_df3.drop(columns='fold',inplace=True)\n",
    "    eq_df3.drop(columns='salience',inplace=True)\n",
    "    X_train = eq_df3.iloc[:,1:].values\n",
    "    y_train = eq_df3.iloc[:,0].values\n",
    "    \n",
    "#     X_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     X_val = X_val.iloc[:,1:].values\n",
    "#     y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "#     y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    X_val = eq_df2[eq_df2['fold'] == dropfold].copy()\n",
    "    X_val.drop(columns='fold',inplace=True)\n",
    "    X_val.drop(columns='salience',inplace=True)\n",
    "    X_val = X_val.iloc[:,1:].values\n",
    "    y_val = eq_df2[eq_df2['fold'] == dropfold]\n",
    "    y_val = y_val.iloc[:,0].values\n",
    "    \n",
    "    voter_list = []\n",
    "    \n",
    "    for i in range(num_voters):\n",
    "        voter_list.append(voter_tuple(i))\n",
    "\n",
    "#     mlp.fit(X_train, y_train)\n",
    "    vote_class = VotingClassifier(estimators=voter_list,\n",
    "                 voting='soft', n_jobs=4)\n",
    "    vote_class = vote_class.fit(X_train, y_train)\n",
    "#     acc = 100*Fmeasure(y_val, mlp.predict(X_val),7)\n",
    "    recall = np.round(100*TPR(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    prec = np.round(100*precision(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "    Fmeas = np.round(100*Fmeasure(y_val, vote_class.predict(X_val),10)[6],2)\n",
    "#     acc = 100*TPR(y_val, mlp.predict(X_val),7)[5]\n",
    "    print(\"Validation TPR of\", recall, \",\\n \\tprecision of \", prec, \",\\n \\tand Fmeasure of\", Fmeas, \"on fold\", str(dropfold))\n",
    "    accuracy_vec[dropfold-1] = recall\n",
    "    dump(vote_class, 'hive_mind_democracy_fold'+str(dropfold)+'.joblib') \n",
    "    \n",
    "print(accuracy_vec)\n",
    "accuracy_vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('hive_mind_democracy_fold10.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b262de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.drop(columns='salience',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_val, clf.predict(X_val)),display_labels=classlabels)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3175fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
