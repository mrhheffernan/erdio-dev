{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NOTE: librosa dependencies apparently require specific versions of numpy, try numpy==1.21.4\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f4c40",
   "metadata": {},
   "source": [
    "Dataset explored is UrbanSound8K:\n",
    "\n",
    "J. Salamon, C. Jacoby and J. P. Bello, \"A Dataset and Taxonomy for Urban Sound Research\", \n",
    "22nd ACM International Conference on Multimedia, Orlando USA, Nov. 2014.\n",
    "\n",
    "https://urbansounddataset.weebly.com/urbansound8k.html\n",
    "\n",
    "https://zenodo.org/record/1203745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e356041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data should be placed in the \"large_data/\" directory, which is not staged in the git repo\n",
    "metadata = pd.read_csv('./large_data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.info()\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f216ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load wav file with librosa, given a row from metadata table\n",
    "def load_data(meta_row):\n",
    "    filename = meta_row['slice_file_name']\n",
    "    filepath = f'large_data/UrbanSound8K/audio/fold{meta_row[\"fold\"]}/'\n",
    "    return librosa.load(filepath+filename,sr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e086f2",
   "metadata": {},
   "source": [
    "The various audiofiles do not exhibit a uniform length or sampling rate. As such we aim to do some pre-classification analysis to generate a uniform observable vector.\n",
    "\n",
    "For this reason we are going to take inspiration from the idea of a music \"equalizer\" scale. We will break down the fourier transform of each audio section into a number of human audible frequencies, as well as the sub-audible and supra-audible sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Siren\n",
    "# row_ind = metadata.loc[514]\n",
    "# test_y, sr = load_data(row_ind)\n",
    "\n",
    "# # music\n",
    "# row_ind = metadata.loc[97]\n",
    "# test_y, sr = load_data(row_ind)\n",
    "\n",
    "# # car horn\n",
    "# row_ind = metadata.loc[13]\n",
    "# test_y, sr = load_data(row_ind)\n",
    "\n",
    "## chilren\n",
    "# row_ind = metadata.loc[3]\n",
    "# test_y, sr = load_data(row_ind)\n",
    "\n",
    "## jackhammer\n",
    "# row_ind = metadata.loc[173]\n",
    "# test_y, sr = load_data(row_ind)\n",
    "\n",
    "## gun shot\n",
    "row_ind = metadata.loc[106]\n",
    "test_y, sr = load_data(row_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_y)\n",
    "\n",
    "t = round(row_ind[\"end\"]-row_ind[\"start\"],3)\n",
    "dt = t/len(test_y)\n",
    "print(dt)\n",
    "\n",
    "k = np.fft.fftfreq(len(test_y), d=dt)\n",
    "print(k[1])\n",
    "\n",
    "yk = np.fft.fft(test_y)\n",
    "mag_yk = np.abs(yk)\n",
    "mag_yk = mag_yk[:len(mag_yk)//2]\n",
    "\n",
    "test_y2 = np.sqrt(test_y*test_y)\n",
    "yk2 = np.fft.fft(test_y2)\n",
    "mag_yk2 = np.abs(yk2)\n",
    "mag_yk2 = mag_yk2[:len(mag_yk2)//2]\n",
    "\n",
    "filttest = yk * np.exp(-k*k/10000000)\n",
    "test_back = np.fft.ifft(filttest)\n",
    "\n",
    "test_y.max()\n",
    "\n",
    "np.sqrt(test_y2.mean())\n",
    "\n",
    "Crestfactor = test_y.max()/np.sqrt(test_y2.mean())\n",
    "Crestfactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844592f3",
   "metadata": {},
   "source": [
    "After initial exploration of the data I noticed that a number of the audio samples have significant \"room noise\" present. In an attempt to clean this up I'm taking the hilbert transform (extracts the instantaneous amplitude of a signal). Smoothing this transform and dividing by the root mean square power should then amplify the parts of the signal that are large in amplitude, while minimizing the areas that are simply a constant amplitude \"hum\". Low crest factor systems will be largely unaffected as the root mean square will be similar to the root mean square of the signal for such signals. Finally we ensure that the maximum amplitude of the signal is scaled to be equal to the input signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1451130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfiltered hilbert scaling\n",
    "testwav = test_y * np.abs(np.abs(scipy.signal.hilbert(test_y)))/np.sqrt((test_y*test_y).mean())\n",
    "testwav *= test_y.max() / testwav.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ee442",
   "metadata": {},
   "outputs": [],
   "source": [
    "hil = np.abs(scipy.signal.hilbert(test_y))\n",
    "plt.plot(hil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363813f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilk = np.fft.fft(hil)\n",
    "hilk *= np.exp(-k*k / (2*10**2))\n",
    "hil2 = np.fft.ifft(hilk)\n",
    "hil2 = np.abs(hil2)\n",
    "hil2 *= hil.max() / hil2.max()\n",
    "plt.plot(hil)\n",
    "plt.plot(np.abs(hil2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ac0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered hilbert scaling\n",
    "testwav2 = test_y * hil2/np.sqrt((test_y*test_y).mean())\n",
    "testwav2 *= test_y.max() / testwav2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(test_y / test_y.max(),rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98e02e",
   "metadata": {},
   "source": [
    "Check the audio samples against one another to see if our attempts at minimizing room noise were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(testwav / testwav.max() * test_y.max(),rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(testwav2 / testwav2.max() * test_y.max(),rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c241e9c",
   "metadata": {},
   "source": [
    "Note that the version with the filtered hilbert transform acting as the instantaneous amplitude has less distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fae22c",
   "metadata": {},
   "source": [
    "We now generate the equilizer values by manually summing over the relevent portions of fourier space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_cutoffs = [20.0, 40.0, 80.0, 160.0, 300.0, 600.0, 1200.0, 2400.0, 5000.0, 10000.0, 20000.0, np.inf]\n",
    "equilizer = np.zeros(12)\n",
    "equilizer2 = np.zeros(12)\n",
    "equilizer3 = np.zeros(12)\n",
    "# equilizer4 = np.zeros(12)\n",
    "\n",
    "ykclean = np.fft.fft(testwav)\n",
    "mag_ykclean = np.abs(ykclean)\n",
    "mag_ykclean = mag_ykclean[:len(mag_ykclean)//2]\n",
    "\n",
    "ykclean2 = np.fft.fft(testwav2)\n",
    "mag_ykclean2 = np.abs(ykclean2)\n",
    "mag_ykclean2 = mag_ykclean2[:len(mag_ykclean2)//2]\n",
    "\n",
    "# ykclean3 = np.fft.fft(testwav3)\n",
    "# mag_ykclean3 = np.abs(ykclean3)\n",
    "# mag_ykclean3 = mag_ykclean3[:len(mag_ykclean3)//2]\n",
    "\n",
    "for i in range(0,12):\n",
    "    index = 0\n",
    "    num = 0\n",
    "    while ((index < len(mag_yk)) & (k[index] < eq_cutoffs[i])):\n",
    "        equilizer[i] += mag_yk[index]\n",
    "        equilizer2[i] += mag_ykclean[index]\n",
    "        equilizer3[i] += mag_ykclean2[index]\n",
    "#         equilizer4[i] += mag_ykclean3[index]\n",
    "        index += 1\n",
    "        num += 1\n",
    "    equilizer[i] /= num\n",
    "    equilizer2[i] /= num\n",
    "    equilizer3[i] /= num\n",
    "#     equilizer4[i] /= num\n",
    "    \n",
    "equilizer /= equilizer.max()\n",
    "equilizer2 /= equilizer2.max()\n",
    "equilizer3 /= equilizer3.max()\n",
    "# equilizer4 /= equilizer4.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4834b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(equilizer)\n",
    "print(equilizer2)\n",
    "print(equilizer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c90a7d",
   "metadata": {},
   "source": [
    "Sanity check with some plots. We notice that the unfiltered version of our clean up step displays distortion in the numerical data as well as testing by ear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(0,12),equilizer)\n",
    "plt.scatter(range(0,12),equilizer2)\n",
    "plt.scatter(range(0,12),equilizer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(0,12),np.log(equilizer)/np.log(10.0))\n",
    "plt.scatter(range(0,12),np.log(equilizer2)/np.log(10.0))\n",
    "plt.scatter(range(0,12),np.log(equilizer3)/np.log(10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1d0e8",
   "metadata": {},
   "source": [
    "We have been iterating through feature selection, and fitting, and examination of the confusion matrix shows that\n",
    "1. The classifier stuggles to differentiate between music and other types of data.\n",
    "2. Gun shots and children playing are often paired in the confusion matrix.\n",
    "\n",
    "We expect that children playing should be a much more \"musical\" type of sound than gun shots. For these two reasons we are going to try and extract some music based features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62f3b5",
   "metadata": {},
   "source": [
    "Librosa has a function to decompose the harmonic and percussive components of a spectrogram. This seems to be done by checking for peaks in the fourier domain (harmonic) and time domain (percussive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d28815",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = librosa.stft(testwav2 / testwav2.max())\n",
    "y_harmonic, y_percussive = librosa.decompose.hpss(D,margin=16.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee31c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(y_harmonic),ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f205bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(y_percussive),ref=np.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826b076",
   "metadata": {},
   "source": [
    "The decomposition loses a certain amount of power based on the 'margin' command which essentially sets how harsh the decomposition should be. For this reason we are going to rescale the power such that the sum of the two components still holds the same level of total power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635458aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = librosa.stft(testwav2 / testwav2.max())\n",
    "y_harmonic, y_percussive = librosa.decompose.hpss(D,margin=16.0)\n",
    "y_p = librosa.istft(y_percussive, length=len(testwav2))\n",
    "y_h = librosa.istft(y_harmonic, length=len(testwav2))\n",
    "Ptot = (testwav2**2).mean()\n",
    "ynorm = testwav2 / np.sqrt(Ptot)\n",
    "Pnorm = (ynorm**2).mean()\n",
    "P_p = (y_p**2).mean()\n",
    "P_h = (y_h**2).mean()\n",
    "Anorm = np.sqrt(Pnorm/(P_h+P_p))\n",
    "y_p *= Anorm\n",
    "y_h *= Anorm\n",
    "P_p = (y_p**2).mean()\n",
    "P_h = (y_h**2).mean()\n",
    "\n",
    "print(Pnorm, P_p, P_h, (P_h + P_p))\n",
    "plt.figure()\n",
    "plt.plot(ynorm)\n",
    "plt.figure()\n",
    "plt.plot(y_h)\n",
    "plt.figure()\n",
    "plt.plot(y_p)\n",
    "plt.figure()\n",
    "\n",
    "y_percussive = librosa.stft(y_p)\n",
    "y_harmonic = librosa.stft(y_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd26b1",
   "metadata": {},
   "source": [
    "From the harmonic component we are going to generate a measure of the harmonics within the sound wave. A great deal of music is made up of chords from major thirds, minor thirds, major fifths, and a triplet consisting of a base frequency with its major third and major fifth.\n",
    "\n",
    "The first thing we are going to do is extract the mean power in the various frequencies corresponding to different MIDI keys. A major third is then a pair consisting of a base frequency (MIDI $n$) and the key whose central frequency is closest to $3 f_n /2$. In a MIDI keyboard this then is the pair (MIDI $n$)+(MIDI $n+4$). Similarly minor thirds are (MIDI $n$)+(MIDI $n+3$), and major fifths are (MIDI $n$)+(MIDI $n+7$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_k = np.fft.fftfreq(np.size(y_harmonic,0), d=dt)\n",
    "fbins = []\n",
    "keypitch = []\n",
    "midi = []\n",
    "maxlen=np.size(y_harmonic,0)\n",
    "p = -69\n",
    "kmin = 440*2**((p - 0.5)/12)\n",
    "kmax = 440*2**((p+0.5)/12)\n",
    "while kmax <= 20000:\n",
    "    kmin = 440*2**((p - 0.5)/12)\n",
    "    kmax = 440*2**((p+0.5)/12)\n",
    "    if (len(np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),0])) != 0) :\n",
    "        sumbin = np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),0]).sum() / len(np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),0]))\n",
    "    else:\n",
    "        sumbin = 0\n",
    "    fbins.append(sumbin)\n",
    "    keypitch.append(440*2**(p/12))\n",
    "    midi.append(p+69)\n",
    "    p += 1\n",
    "print(p)\n",
    "plt.figure()\n",
    "plt.plot(midi, fbins)\n",
    "len(librosa.util.peak_pick(np.asarray(fbins), pre_max=1, post_max=1, pre_avg=1, post_avg=1, delta=0, wait=0))\n",
    "peaks = librosa.util.localmax(np.asarray(fbins))\n",
    "plt.figure()\n",
    "plt.plot(np.asarray(peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "maj3 = []\n",
    "min3 = []\n",
    "maj5 = []\n",
    "majchord = []\n",
    "fbins = np.asarray(fbins)\n",
    "favg = fbins[fbins > 0].max()\n",
    "for i in range(len(fbins)-4):\n",
    "    maj3.append(peaks[i]*peaks[i+4]*(fbins[i] + fbins[i+4])/favg)\n",
    "for i in range(len(fbins)-3):\n",
    "    min3.append(peaks[i]*peaks[i+3]*(fbins[i] + fbins[i+3])/favg)\n",
    "for i in range(len(fbins)-7):\n",
    "    maj5.append(peaks[i]*peaks[i+7]*(fbins[i] + fbins[i+7])/favg)\n",
    "    majchord.append(peaks[i]*peaks[i+4]*peaks[i+7]*(fbins[i] + fbins[i+4] + fbins[i+7])/favg)\n",
    "\n",
    "\n",
    "maj3 = np.asarray(maj3)\n",
    "min3 = np.asarray(min3)\n",
    "maj5 = np.asarray(maj5)\n",
    "majchord = np.asarray(majchord)\n",
    "harmonicality  = len(maj3[np.log10(maj3+1e-12)>=-0.5]) + len(min3[np.log10(min3+1e-12)>=-0.5])+len(maj5[np.log10(maj5+1e-12)>=-0.5])+len(majchord[np.log10(majchord+1e-12)>=-0.5])\n",
    "print(\"there are \",len(maj3[np.log10(maj3+1e-12)>=-0.5]),\" major third(s), \",\n",
    "      len(min3[np.log10(min3+1e-12)>=-0.5]),\" minor third(s), \",\n",
    "      len(maj5[np.log10(maj5+1e-12)>=-0.5]),\" major third(s), and \",\n",
    "      len(majchord[np.log10(majchord+1e-12)>=-0.5]),\" major chord(s).\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot((np.asarray(maj3) +1e-9))\n",
    "plt.figure()\n",
    "plt.plot((np.asarray(min3) +1e-9))\n",
    "plt.figure()\n",
    "plt.plot((np.asarray(maj5) +1e-9))\n",
    "plt.figure()\n",
    "plt.plot((np.asarray(majchord) +1e-9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a3c9d",
   "metadata": {},
   "source": [
    "We also want to recognize the percussive hits. This is easy enough to do using the librosa onset_strength function. We then use peak detection to generate the total number of percussive crashes in the soundwave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59244776",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = librosa.istft(y_percussive, length=len(test_y))\n",
    "times = librosa.times_like(y_percussive)\n",
    "plt.plot(dt*range(len(y_out)),y_out)\n",
    "onset_env = librosa.onset.onset_strength(y=y_out, sr=sr,\n",
    "#                                           hop_length=512,\n",
    "                                         max_size=5,\n",
    "                                          aggregate=np.median)\n",
    "plt.figure()\n",
    "plt.plot(times/2, onset_env / onset_env.max())\n",
    "perc_peaks = librosa.util.peak_pick(onset_env, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.5, wait=0)\n",
    "# onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)\n",
    "# onset_frames = librosa.onset.onset_detect(y = y_out, sr=sr)\n",
    "\n",
    "print(\"percussive peaks are at \", perc_peaks, \"for a total length of \", len(perc_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20997e9f",
   "metadata": {},
   "source": [
    "Make a function to do the cleanup and save the results as a nice, compact csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b238f4c",
   "metadata": {},
   "source": [
    "We have iterated on the features a number of times, as can be seen by the commented out headers. In this version we include salience (whether the sound is background or foreground), as well as the power in the percussive and harmonic parts, and the number of percussive hits, and the time averaged number of harmonic chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(filenm):\n",
    "    file = open(filenm,'w+')\n",
    "#     file.write(\"class,eq_0,eq_20,eq_40,eq_80,eq_160,eq_300,eq_600,eq_1200,eq_2400,eq_5000,eq_10000,eq_20000,crestfactor,fold\\n\")\n",
    "#     file.write(\"class,eq_0,eq_10,eq_20,eq_30,eq_40,eq_60,eq_80,eq_120,eq_160,eq_230,eq_300,eq_450,eq_600,eq_900,eq_1200,eq_1800,eq_2400,eq_3700,eq_5000,eq_7500,eq_10000,eq_15000,eq_20000,crestfactor,thirds,fifths,fold\\n\")\n",
    "#     file.write(\"class,eq_0,eq_20,eq_40,eq_80,eq_160,eq_300,eq_600,eq_1200,eq_2400,eq_5000,eq_10000,eq_20000,crestfactor,musicality,fold\\n\")\n",
    "    file.write(\"class,eq_0,eq_10,eq_20,eq_30,eq_40,eq_60,eq_80,eq_120,eq_160,eq_230,eq_300,eq_450,eq_600,eq_900,eq_1200,eq_1800,eq_2400,eq_3700,eq_5000,eq_7500,eq_10000,eq_15000,eq_20000,crestfactor,salience,harmonic_power,percussive_power,harmonic_hits,percussive_hits,fold\\n\")\n",
    "\n",
    "\n",
    "#     eq_cutoffs = [20.0, 40.0, 80.0, 160.0, 300.0, 600.0, 1200.0, 2400.0, 5000.0, 10000.0, 20000.0, np.inf]\n",
    "    eq_cutoffs = [10.0, 20.0, 30.0, 40.0, 60.0, 80.0, 120.0, 160.0, 230.0, 300.0, 450.0, 600.0, 900.0, 1200.0, 1800.0, 2400.0, 3700.0, 5000.0, 7500.0, 10000.0, 15000.0, 20000.0, np.inf]\n",
    "\n",
    "\n",
    "    for row_ind in range(0,len(metadata)):\n",
    "        row = metadata.loc[row_ind]\n",
    "        y,sr = load_data(metadata.loc[row_ind])\n",
    "        classifier = metadata['class'][row_ind]\n",
    "        foldinfo = metadata['fold'][row_ind]\n",
    "        t = round(row[\"end\"]-row[\"start\"],3)\n",
    "        dt = t/len(y)\n",
    "        k = np.fft.fftfreq(len(y), d=dt)\n",
    "#         k = k[:len(k)//2]\n",
    "        sal = row[\"salience\"]\n",
    "        \n",
    "        hil = np.abs(scipy.signal.hilbert(y))\n",
    "        hilk = np.fft.fft(hil)\n",
    "        hilk *= np.exp(-k*k / (2*10**2))\n",
    "        hil2 = np.fft.ifft(hilk)\n",
    "        hil2 = np.abs(hil2)\n",
    "        hil2 *= hil.max() / hil2.max()\n",
    "        filt_y = y * hil2/np.sqrt((y*y).mean())\n",
    "        filt_y *= y.max() / filt_y.max()\n",
    "        y_sq = filt_y*filt_y\n",
    "        Cr = filt_y.max() / np.sqrt(y_sq.mean())\n",
    "        \n",
    "        yk = np.fft.fft(filt_y)\n",
    "        mag_yk = np.abs(yk)\n",
    "        mag_yk = mag_yk[:len(mag_yk)//2]\n",
    "        \n",
    "        D = librosa.stft(filt_y / filt_y.max())\n",
    "        y_harmonic, y_percussive = librosa.decompose.hpss(D,margin=16.0)\n",
    "        y_p = librosa.istft(y_percussive, length=len(filt_y))\n",
    "        y_h = librosa.istft(y_harmonic, length=len(filt_y))\n",
    "        Ptot = (filt_y**2).mean()\n",
    "        ynorm = filt_y / np.sqrt(Ptot)\n",
    "        Pnorm = (ynorm**2).mean()\n",
    "        P_p = (y_p**2).mean()\n",
    "        P_h = (y_h**2).mean()\n",
    "        Anorm = np.sqrt(Pnorm/(P_h+P_p))\n",
    "        y_p *= Anorm\n",
    "        y_h *= Anorm\n",
    "        \n",
    "        y_percussive = librosa.stft(y_p)\n",
    "        y_harmonic = librosa.stft(y_h)\n",
    "        \n",
    "        st_k = np.fft.fftfreq(np.size(y_harmonic,0), d=dt)\n",
    "        fbins = []\n",
    "        keypitch = []\n",
    "        midi = []\n",
    "        maxlen=np.size(y_harmonic,0)\n",
    "        p = -69\n",
    "        kmin = 440*2**((p - 0.5)/12)\n",
    "        kmax = 440*2**((p+0.5)/12)\n",
    "        while kmax <= 20000:\n",
    "            kmin = 440*2**((p - 0.5)/12)\n",
    "            kmax = 440*2**((p+0.5)/12)\n",
    "            keypitch.append(440*2**(p/12))\n",
    "            midi.append(p+69)\n",
    "            p += 1\n",
    "            \n",
    "            \n",
    "        harmonicality = 0\n",
    "        for tm in range(size(y_harmonic,1)):\n",
    "            p = -69\n",
    "            kmin = 440*2**((p - 0.5)/12)\n",
    "            kmax = 440*2**((p+0.5)/12)    \n",
    "            while kmax <= 20000:\n",
    "                kmin = 440*2**((p - 0.5)/12)\n",
    "                kmax = 440*2**((p+0.5)/12)\n",
    "                if (len(np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),i])) != 0) :\n",
    "                    sumbin = np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),tm]).sum() / len(np.abs(y_harmonic[(st_k[:maxlen] <= kmax) & (st_k[:maxlen] > kmin),tm]))\n",
    "                else:\n",
    "                    sumbin = 0\n",
    "                fbins.append(sumbin)\n",
    "                p += 1\n",
    "\n",
    "            peaks = librosa.util.localmax(np.asarray(fbins))\n",
    "\n",
    "            maj3 = []\n",
    "            min3 = []\n",
    "            maj5 = []\n",
    "            majchord = []\n",
    "            fbins = np.asarray(fbins)\n",
    "            if len(fbins[fbins > 0] > 0):\n",
    "                favg = fbins[fbins > 0].max()\n",
    "            else:\n",
    "                favg = 1\n",
    "            for i in range(len(fbins)-4):\n",
    "                maj3.append(peaks[i]*peaks[i+4]*(fbins[i] + fbins[i+4])/favg)\n",
    "            for i in range(len(fbins)-3):\n",
    "                min3.append(peaks[i]*peaks[i+3]*(fbins[i] + fbins[i+3])/favg)\n",
    "            for i in range(len(fbins)-7):\n",
    "                maj5.append(peaks[i]*peaks[i+7]*(fbins[i] + fbins[i+7])/favg)\n",
    "                majchord.append(peaks[i]*peaks[i+4]*peaks[i+7]*(fbins[i] + fbins[i+4] + fbins[i+7])/favg)\n",
    "\n",
    "\n",
    "            maj3 = np.asarray(maj3)\n",
    "            min3 = np.asarray(min3)\n",
    "            maj5 = np.asarray(maj5)\n",
    "            majchord = np.asarray(majchord)\n",
    "            maj3 = len(maj3[np.log10(maj3 + 1e-12)>=-0.5])\n",
    "            min3 = len(min3[np.log10(min3 + 1e-12)>=-0.5])\n",
    "            maj5 = len(maj5[np.log10(maj5 + 1e-12)>=-0.5])\n",
    "            majchord = len(majchord[np.log10(majchord + 1e-12)>=-0.5])\n",
    "            harmonicality += maj3 + min3 + maj5 + majchord\n",
    "            \n",
    "        harmrate = harmonicality / size(y_harmonic,1)\n",
    "        \n",
    "        y_out = librosa.istft(y_percussive, length=len(filt_y))\n",
    "\n",
    "        onset_env = librosa.onset.onset_strength(y=y_out, sr=sr,\n",
    "                                                 max_size=5,\n",
    "                                                  aggregate=np.median)\n",
    "\n",
    "        perc_peaks = librosa.util.peak_pick(onset_env, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.5, wait=0)\n",
    "\n",
    "\n",
    "        perc_rate = len(perc_peaks) #/ t\n",
    "        \n",
    "        equilizer = np.zeros(len(eq_cutoffs))\n",
    "        for i in range(len(equilizer)):\n",
    "            index = 0\n",
    "            num = 0\n",
    "            while ((index < len(mag_yk)) & (k[index] < eq_cutoffs[i])):\n",
    "                equilizer[i] += mag_yk[index]\n",
    "                index += 1\n",
    "                num += 1\n",
    "            equilizer[i] /= num\n",
    "            \n",
    "        file.write(classifier)\n",
    "        for i in range(len(eq_cutoffs)):\n",
    "            file.write(\",\"+str(equilizer[i]))\n",
    "        \n",
    "        file.write(\",\"+str(Cr))\n",
    "        file.write(\",\"+str(sal))\n",
    "        file.write(\",\"+str(P_h))\n",
    "        file.write(\",\"+str(P_p))\n",
    "        file.write(\",\"+str(harmrate))\n",
    "        file.write(\",\"+str(perc_rate))\n",
    "        file.write(\",\"+str(foldinfo)+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv('./large_data/filt_equilizer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af757e30",
   "metadata": {},
   "source": [
    "Check that everything worked and we can load our file as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd37fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df = pd.read_csv('./large_data/filt_equilizer_data.csv')\n",
    "display(eq_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
